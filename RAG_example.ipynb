{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reyagao/Health_Chatbot/blob/main/RAG_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju_PGpFx7yQh"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/sergiopaniego/RAG_local_tutorial/blob/main/example_rag.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-hijAaV7yQi"
      },
      "source": [
        "# Simple RAG example with Langchain, Ollama and and open-source LLM model\n",
        "\n",
        "In this example, we first connect to an LLM locally and make request to the LLM that Ollama is serving using LangChain. After that, we generate our RAG application from a PDF file and extract details from that document.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2023/07/langchain3.png\" alt=\"Langchain Logo\" width=\"20%\">\n",
        "  <img src=\"https://bookface-images.s3.amazonaws.com/logos/ee60f430e8cb6ae769306860a9c03b2672e0eaf2.png\" alt=\"Ollama Logo\" width=\"20%\">\n",
        "</p>\n",
        "\n",
        "Sources:\n",
        "\n",
        "* https://github.com/svpino/llm\n",
        "* https://github.com/AIAnytime/Gemma-7B-RAG-using-Ollama/blob/main/Ollama%20Gemma.ipynb\n",
        "* https://www.youtube.com/watch?v=-MexTC18h20&ab_channel=AIAnytime\n",
        "* https://www.youtube.com/watch?v=HRvyei7vFSM&ab_channel=Underfitted\n",
        "\n",
        "\n",
        "# Requirements\n",
        "\n",
        "* Ollama installed locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msI5F7j_7yQi"
      },
      "source": [
        "# Install the requirements\n",
        "\n",
        "If an error is raised related to docarray, refer to this solution: https://stackoverflow.com/questions/76880224/error-using-using-docarrayinmemorysearch-in-langchain-could-not-import-docarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I_5iwDCc7yQi",
        "outputId": "3b417d64-4bbc-4ed0-ac97-052f9e4cbcb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (0.3.37)\n",
            "Collecting pinecone<6.0.0,>=5.4.0 (from langchain_pinecone)\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting aiohttp<3.11,>=3.10 (from langchain_pinecone)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (1.26.4)\n",
            "Collecting langchain-tests<1.0.0,>=0.3.7 (from langchain_pinecone)\n",
            "  Downloading langchain_tests-0.3.12-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.10.6)\n",
            "Requirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (8.3.4)\n",
            "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading pytest_asyncio-0.25.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.28.1)\n",
            "Collecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading syrupy-4.8.2-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone)\n",
            "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2025.1.31)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone<6.0.0,>=5.4.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone<6.0.0,>=5.4.0->langchain_pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.27.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone<6.0.0,>=5.4.0->langchain_pinecone) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain_pinecone) (0.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.3.1)\n",
            "Downloading langchain_pinecone-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tests-0.3.12-py3-none-any.whl (37 kB)\n",
            "Downloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading pytest_asyncio-0.25.3-py3-none-any.whl (19 kB)\n",
            "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading syrupy-4.8.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-interface, syrupy, pytest-socket, pytest-asyncio, pinecone-plugin-inference, aiohttp, pinecone, langchain-tests, langchain_pinecone\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.12\n",
            "    Uninstalling aiohttp-3.11.12:\n",
            "      Successfully uninstalled aiohttp-3.11.12\n",
            "Successfully installed aiohttp-3.10.11 langchain-tests-0.3.12 langchain_pinecone-0.2.3 pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7 pytest-asyncio-0.25.3 pytest-socket-0.7.0 syrupy-4.8.2\n",
            "Requirement already satisfied: langchain[docarray] in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "\u001b[33mWARNING: langchain 0.3.19 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (3.10.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain[docarray]) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain[docarray]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain[docarray]) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain[docarray]) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[docarray]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[docarray]) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[docarray]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[docarray]) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[docarray]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[docarray]) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[docarray]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[docarray]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[docarray]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[docarray]) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain[docarray]) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[docarray]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[docarray]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[docarray]) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain[docarray]) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (0.2.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[docarray]) (1.3.1)\n",
            "Collecting docarray\n",
            "  Downloading docarray-0.40.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from docarray) (1.26.4)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.11/dist-packages (from docarray) (3.10.15)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from docarray) (2.10.6)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from docarray) (13.9.4)\n",
            "Collecting types-requests>=2.28.11.6 (from docarray)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from docarray)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray) (2.18.0)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.11/dist-packages (from types-requests>=2.28.11.6->docarray) (2.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->docarray)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
            "Downloading docarray-0.40.0-py3-none-any.whl (270 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m270.2/270.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: types-requests, mypy-extensions, typing-inspect, docarray\n",
            "Successfully installed docarray-0.40.0 mypy-extensions-1.0.0 types-requests-2.32.0.20241016 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install langchain\n",
        "!pip3 install langchain_pinecone\n",
        "!pip3 install langchain[docarray]\n",
        "!pip3 install docarray\n",
        "!pip3 install pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luV_AH067yQj"
      },
      "source": [
        "# Select the LLM model to use\n",
        "\n",
        "The model must be downloaded locally to be used, so if you want to run llama3, you should run:\n",
        "\n",
        "```\n",
        "\n",
        "ollama pull llama3\n",
        "\n",
        "```\n",
        "\n",
        "Check the list of models available for Ollama here: https://ollama.com/library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xq_J60gb7yQj"
      },
      "outputs": [],
      "source": [
        "#MODEL = \"gpt-3.5-turbo\"\n",
        "#MODEL = \"mixtral:8x7b\"\n",
        "#MODEL = \"gemma:7b\"\n",
        "#MODEL = \"llama2\"\n",
        "MODEL = \"llama3\" # https://ollama.com/library/llama3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-ollama"
      ],
      "metadata": {
        "id": "5vEMAGnNBhXP",
        "outputId": "0fa883d0-0a69-4089-f0b4-05221ce0d3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-ollama\n",
            "  Downloading langchain_ollama-0.2.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama) (0.3.37)\n",
            "Collecting ollama<1,>=0.4.4 (from langchain-ollama)\n",
            "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.10.6)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
            "Downloading langchain_ollama-0.2.3-py3-none-any.whl (19 kB)\n",
            "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama, langchain-ollama\n",
            "Successfully installed langchain-ollama-0.2.3 ollama-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHCvEvoP7yQj"
      },
      "source": [
        "# We instanciate the LLM model and the Embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8UWGw6jx7yQj",
        "outputId": "93a03d98-eb09-4ae1-ef79-a6704e1c3547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üòä Ollama is a popular online tool for creating and sharing voice messages, and I'd be happy to introduce you to its usage method. Here's a step-by-step guide:\n",
            "\n",
            "**What is Ollama?**\n",
            "Before we dive into the usage method, let me briefly explain what Ollama is. Ollama is an online platform that allows users to create and share voice messages anonymously. It's like a digital post-it note, but instead of leaving a written message, you leave a spoken one.\n",
            "\n",
            "**How to use Ollama:**\n",
            "\n",
            "1. **Visit the website**: Go to [Ollama.com](http://ollama.com) in your web browser.\n",
            "2. **Create an account**: Click on \"Sign up\" and enter your email address, password, and username (optional).\n",
            "3. **Choose a theme**: Select a theme for your voice message from the available options or create your own.\n",
            "4. **Record your message**: Use the built-in microphone to record your voice message. You can speak as much or as little as you like.\n",
            "5. **Add audio effects (optional)**: If you want to add some flair to your message, you can use Ollama's built-in audio effects, such as echo, reverb, or speed.\n",
            "6. **Share your message**: Once you're happy with your recording, you can share it anonymously on the internet. You can share a link to your message via social media, messaging apps, or email.\n",
            "\n",
            "**Some additional tips:**\n",
            "\n",
            "* Keep in mind that Ollama is an anonymous platform, so be mindful of what you say and how you represent yourself.\n",
            "* Be respectful of others' messages and don't spam or harass other users.\n",
            "* If you want to leave a comment on someone else's message, you can do so by clicking the \"Comment\" button.\n",
            "\n",
            "That's it! Ollama is a fun way to share your thoughts, opinions, or just have some creative fun. Give it a try and see what kind of messages you come up with üìû\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain_ollama import OllamaLLM\n",
        "\n",
        "model = OllamaLLM(base_url=\"http://ab65-217-117-226-146.ngrok-free.app\", model=\"llama3\")\n",
        "response = model.invoke(\"‰Ω†Â•ΩÔºå‰ªãÁªç‰∏Ä‰∏ãOllamaÁöÑ‰ΩøÁî®ÊñπÊ≥ï\")\n",
        "print(response)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "go1j_s257yQk",
        "outputId": "a2883b79-f719-4802-b16f-22d4724a23be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The answer to 2+2 is 4.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model.invoke(\"Waht is 2+2?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quDhqQ107yQk"
      },
      "source": [
        "## Using a parser provided by LangChain, we can transform the LLM output to something more suitable to be read"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "031OOHlk7yQk"
      },
      "source": [
        "# We generate the template for the conversation with the instruct-based LLM\n",
        "\n",
        "We can create a template to structure the conversation effectively.\n",
        "\n",
        "This template allows us to provide some general context to the Language Learning Model (LLM), which will be utilized for every prompt. This ensures that the model has a consistent background understanding for all interactions.\n",
        "\n",
        "Additionally, we can include specific context relevant to the particular prompt. This helps the model understand the immediate scenario or topic before addressing the actual question. Following this specific context, we then present the actual question we want the model to answer.\n",
        "\n",
        "By using this approach, we enhance the model's ability to generate accurate and relevant responses based on both the general and specific contexts provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "smxhTUU87yQk",
        "outputId": "b9691edd-877c-4f28-8079-87fba1440a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, answer with \"I don\\'t know\".\\n\\nContext: Here is some context\\n\\nQuestion: Here is a question\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Answer the question based on the context below. If you can't\n",
        "answer the question, answer with \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt.format(context=\"Here is some context\", question=\"Here is a question\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43K0zSYl7yQk"
      },
      "source": [
        "The model can answer prompts based on the context:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yrCvl0uu7yQk",
        "outputId": "fcbac975-8cd7-446e-e448-7e2a67bc048c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'parser' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0af19c36bbfd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mformatted_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"My parents named me Sergio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"What's your name?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresponse_from_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparsed_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'parser' is not defined"
          ]
        }
      ],
      "source": [
        "formatted_prompt = prompt.format(context=\"My parents named me Sergio\", question=\"What's your name?\")\n",
        "response_from_model = model.invoke(formatted_prompt)\n",
        "parsed_response = parser.parse(response_from_model)\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82Lxusod7yQk"
      },
      "source": [
        "But it can't answer what is not provided as context:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO-hwrwh7yQk",
        "outputId": "95204155-3d30-470d-c80c-9a691b4d155b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't know! The provided context only tells me that your parents named you Sergio, but it doesn't mention anything about your age. I can't infer or guess your age based on this information.\n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = prompt.format(context=\"My parents named me Sergio\", question=\"What's my age?\")\n",
        "response_from_model = model.invoke(formatted_prompt)\n",
        "parsed_response = parser.parse(response_from_model)\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2If5FlJ7yQk"
      },
      "source": [
        "Even previously known info!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t_K6ocI7yQk",
        "outputId": "ae626ad2-80c6-463b-93c5-fcca49b1ff79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't know!\n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = prompt.format(context=\"My parents named me Sergio\", question=\"What is 2+2?\")\n",
        "response_from_model = model.invoke(formatted_prompt)\n",
        "parsed_response = parser.parse(response_from_model)\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0WODwzZ7yQk"
      },
      "source": [
        "# Load an example PDF to do Retrieval Augmented Generation (RAG)\n",
        "\n",
        "For the example, you can select your own PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbYJ5VTb7yQl",
        "outputId": "de4bf6ce-3a50-49bd-cc95-3bcb35a12048"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='teaching/talks\\nUniv ersity and non-univ ersity courses shown\\nüéìCurr ently teaching assistant for:\\nSubject Wher e When\\nArti\\x00cial Intelligence3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n21-22\\n20-21\\nRobotics3rd year Telematics Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n\\x00Couses:\\nCourse name Wher e When\\nIntroduction t o Coding ISDI (DMBA, MBA)December\\n2023 -\\nIntroduction t o Arti\\x00cial Intelligence IES E uropa, MadridNovember\\n2023\\nIntroduction t o Programming with P ython Atenea F ormaci√≥nNovember\\n2023\\nIntroduction t o Arti\\x00cial Intelligence and\\nits A pplicationsAtenea F ormaci√≥n July 2023\\nObject detection and segmentation with\\nTensor\\x00owPlatzi July 2022\\n¬© Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 1/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
              " Document(page_content='üí¨Selected talks:\\nTalk name Wher e When\\nWhat happens when we combine video\\ngames with ChatGPT? Giving lif e to NPCsUbuP arty, Bur gosSeptember\\n2023\\nVision based end-t o-end aut onomous\\ndriving via imitation learningMaster in Ar ti\\x00cial Vision, URJC, MadridMarch\\n2023\\nRL-Studio: A Tool for Reinfor cement\\nLearning Methods in RoboticsROBO T 2022 Conf erence, Zar agozaNovember\\n2022\\nüìñMaster thesis dir ected:\\nThesis name Student When\\nConducci√≥n aut √≥noma en tr √°\\x00co usando\\naprendizaje pr ofundo extr emo a extr emo\\n(Autonomous driving in tr a\\x00c using end-\\nto-end deep learning)Enrique Y . Shinohar a Sot oMaster\\nin\\nArti\\x00cial\\nVision,\\nURJC,\\n2022-\\n2023\\n‚úçReviewer:\\nJournal/Conf erence When\\n(Journal) Exper t Systems 2023\\n(Conf erence) W orkshop on Physical Agents ( WAF) 2023\\n¬© Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 2/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 1}),\n",
              " Document(page_content='üéìPrevious teaching experience:\\nSubject Wher e When\\nModelling and Simulation of Robots3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\nEmbedded and Real Time Systems3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\n¬© Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 3/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 2})]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "\n",
        "loader = PyPDFLoader(\"./files/teaching.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "#pages = loader.load()\n",
        "pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmvMPxFM7yQl",
        "outputId": "62bfd426-a242-4f85-d65c-34c421e0d7ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='teaching/talks\\nUniv ersity and non-univ ersity courses shown\\nüéìCurr ently teaching assistant for:\\nSubject Wher e When\\nArti\\x00cial Intelligence3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n21-22\\n20-21\\nRobotics3rd year Telematics Engineering\\nUniv ersidad Re y Juan Carlos22-23\\n\\x00Couses:\\nCourse name Wher e When\\nIntroduction t o Coding ISDI (DMBA, MBA)December\\n2023 -\\nIntroduction t o Arti\\x00cial Intelligence IES E uropa, MadridNovember\\n2023\\nIntroduction t o Programming with P ython Atenea F ormaci√≥nNovember\\n2023\\nIntroduction t o Arti\\x00cial Intelligence and\\nits A pplicationsAtenea F ormaci√≥n July 2023\\nObject detection and segmentation with\\nTensor\\x00owPlatzi July 2022\\n¬© Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 1/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
              " Document(page_content='üí¨Selected talks:\\nTalk name Wher e When\\nWhat happens when we combine video\\ngames with ChatGPT? Giving lif e to NPCsUbuP arty, Bur gosSeptember\\n2023\\nVision based end-t o-end aut onomous\\ndriving via imitation learningMaster in Ar ti\\x00cial Vision, URJC, MadridMarch\\n2023\\nRL-Studio: A Tool for Reinfor cement\\nLearning Methods in RoboticsROBO T 2022 Conf erence, Zar agozaNovember\\n2022\\nüìñMaster thesis dir ected:\\nThesis name Student When\\nConducci√≥n aut √≥noma en tr √°\\x00co usando\\naprendizaje pr ofundo extr emo a extr emo\\n(Autonomous driving in tr a\\x00c using end-\\nto-end deep learning)Enrique Y . Shinohar a Sot oMaster\\nin\\nArti\\x00cial\\nVision,\\nURJC,\\n2022-\\n2023\\n‚úçReviewer:\\nJournal/Conf erence When\\n(Journal) Exper t Systems 2023\\n(Conf erence) W orkshop on Physical Agents ( WAF) 2023\\n¬© Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 2/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 1}),\n",
              " Document(page_content='üéìPrevious teaching experience:\\nSubject Wher e When\\nModelling and Simulation of Robots3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\nEmbedded and Real Time Systems3rd year Robotics Softwar e Engineering\\nUniv ersidad Re y Juan Carlos21-22\\n20-21\\n¬© Cop yright 2024 Ser gio P aniego. P ower ed b y Jekyll  with al-folio  theme. Hosted b y GitHub P ages .21/6/24, 17:18 teaching/talks | Sergio Paniego\\nhttps://sergiopaniego.github.io/teaching_and_activities/ 3/3', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 2})]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "text_documents = text_splitter.split_documents(pages)[:5]\n",
        "\n",
        "pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL-R5HrI7yQl"
      },
      "source": [
        "# Store the PDF in a vector space.\n",
        "\n",
        "From Langchain docs:\n",
        "\n",
        "`DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.`\n",
        "\n",
        "The execution time of the following block depends on the complexity and longitude of the PDF provided. Try to keep it small and simple for the example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPTsIXNJ7yQl"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "vectorstore = DocArrayInMemorySearch.from_documents(text_documents, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxyMG4pl7yQl"
      },
      "source": [
        "# Create retriever of vectors that are similar to be used as context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY2JwJBs7yQl",
        "outputId": "d4792e01-b29a-424e-d4dc-c09247fd5c4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Introduction t o Coding ISDI (DMBA, MBA)December\\n2023 -', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
              " Document(page_content='teaching/talks\\nUniv ersity and non-univ ersity courses shown\\nüéìCurr ently teaching assistant for:', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
              " Document(page_content='Univ ersidad Re y Juan Carlos22-23\\n21-22\\n20-21\\nRobotics3rd year Telematics Engineering', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0}),\n",
              " Document(page_content='Subject Wher e When\\nArti\\x00cial Intelligence3rd year Robotics Softwar e Engineering', metadata={'source': './files/teaching_talks _ Sergio Paniego.pdf', 'page': 0})]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "retriever.invoke(\"artificial intelligence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRB3qtz17yQl"
      },
      "source": [
        "# Generate conversate with the document to extract the details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur4JsrZl7yQl"
      },
      "outputs": [],
      "source": [
        "# Assuming retriever is an instance of a retriever class and has a method to retrieve context\n",
        "retrieved_context = retriever.invoke(\"artificial intelligence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmw3DoKN7yQl",
        "outputId": "765e6f31-593d-47fc-a85b-52ba96ea9f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are his research interests?\n",
            "Answer: I don't know. The provided context does not mention the specific research interests of Sergio Paniego, but it does show the courses and topics he is teaching or has taught in the past. If you're looking for information on his research interests, I recommend searching for academic articles, presentations, or online profiles where he may have shared his research areas of focus.\n",
            "\n",
            "Question: Does he have teaching experience?\n",
            "Answer: Based on the context, it appears that the individual has teaching experience. The documents mention \"teaching talks\" and \"teaching assistant\", which suggests that they have experience in this area. Therefore, my answer is:\n",
            "\n",
            "Yes, he has teaching experience.\n",
            "\n",
            "Question: Does he know about Tensorflow?\n",
            "Answer: I don't know. The provided context only shows documents related to teaching talks and course information, but it does not mention TensorFlow specifically. Therefore, I cannot determine whether the person knows about TensorFlow based on this information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    \"What are his research interests?\",\n",
        "    \"Does he have teaching experience?\",\n",
        "    \"Does he know about Tensorflow?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
        "    response_from_model = model.invoke(formatted_prompt)\n",
        "    parsed_response = parser.parse(response_from_model)\n",
        "\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {parsed_response}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONINsrKU7yQl"
      },
      "source": [
        "# Loop to ask-answer questions continously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI_tSDfe7yQl"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    print(\"Say 'exit' or 'quit' to exit the loop\")\n",
        "    question = input('User question: ')\n",
        "    print(f\"Question: {question}\")\n",
        "    if question.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Exiting the conversation. Goodbye!\")\n",
        "        break\n",
        "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
        "    response_from_model = model.invoke(formatted_prompt)\n",
        "    parsed_response = parser.parse(response_from_model)\n",
        "    print(f\"Answer: {parsed_response}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}